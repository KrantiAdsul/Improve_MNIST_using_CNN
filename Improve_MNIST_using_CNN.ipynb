{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQjHqsmTAVLU"
   },
   "source": [
    "## Improve MNIST with Convolutions\n",
    "\n",
    "Try to improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer to the model \n",
    "\n",
    "You should stop training once the accuracy goes above this amount. Training must end once it hits the above metric. If it doesn't, then you'll need to redesign your callback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZpztRwBouwYp",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd() \n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\") \n",
    "\n",
    "# Get only training set\n",
    "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n",
    "One important step when dealing with image data is to preprocess the data. During the preprocess step you can apply transformations to the dataset that will be fed into your convolutional neural network.\n",
    "\n",
    "Here we will apply two transformations to the data:\n",
    "- Reshape the data so that it has an extra dimension. The reason for this \n",
    "is that commonly we will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
    "\n",
    "\n",
    "- Normalize the pixel values so that these are values between 0 and 1. We can achieve this by dividing every value in the array by the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reshape_and_normalize\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "    \n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Reshape the images to add an extra dimension\n",
    "    images = images.reshape(60000, 28, 28, 1)\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    images = images / 255.0\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function with the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "\n",
      "Shape of one image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case you run this cell multiple times\n",
    "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path=data_path) \n",
    "\n",
    "# Apply your function\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining your callback\n",
    "\n",
    "Now complete the callback that will ensure that training will stop after an accuracy of 99.5% is reached.\n",
    "\n",
    "Define callback in such a way that it checks for the metric `accuracy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Define the method that checks the accuracy at the end of each epoch\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy')>0.995):\n",
    "                print(\"\\nReached 99.5% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "    \n",
    "\n",
    "### END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Model\n",
    "\n",
    "Finally, complete the `convolutional_model` function below. This function should return your convolutional neural network.\n",
    "\n",
    "**Your model should achieve an accuracy of 99.5% or more before 10 epochs to pass this assignment.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_model\n",
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([ \n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ]) \n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy']) \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1562 - accuracy: 0.9536\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0515 - accuracy: 0.9846\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0317 - accuracy: 0.9905\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.0224 - accuracy: 0.9928\n",
      "Epoch 5/6\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9958\n",
      "Reached 99.5% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0130 - accuracy: 0.9959\n"
     ]
    }
   ],
   "source": [
    "# Save your untrained model\n",
    "model = convolutional_model()\n",
    "\n",
    "# Get number of weights\n",
    "model_params = model.count_params()\n",
    "\n",
    "# Unit test to limit the size of the model\n",
    "assert model_params < 1000000, (\n",
    "    f'Your model has {model_params:,} params. For successful grading, please keep it ' \n",
    "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
    ")\n",
    "\n",
    "# Instantiate the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Train your model (this can take up to 5 minutes)\n",
    "history = model.fit(training_images, training_labels, epochs=6, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see the message that we defined in our callback printed out after less than 10 epochs it means our callback worked as expected. We can also double check by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was trained for 5 epochs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metric was correctly defined.\n"
     ]
    }
   ],
   "source": [
    "if not \"accuracy\" in history.model.metrics_names:\n",
    "    print(\"Use 'accuracy' as metric when compiling your model.\")\n",
    "else:\n",
    "    print(\"The metric was correctly defined.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
